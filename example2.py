# -*- coding: utf-8 -*-
"""Copy of exploreCSR-ML-example_02.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yTT1kikf9xNiBEA-MNItjAKdspWzdHAA

# **Example 02**
In this example, we will construct a neural network to **recognize handwritten digits**. The goal of this neural network will be to **classify** images of handwritten digits into 10 different **classes** (0 through 9).

First, we import the `TensorFlow` and `numpy` libraries.
"""

import tensorflow as tf
import numpy as np

"""Next, we load the MNIST dataset, which has images of handwritten digits (from 0 to 9)."""

data = tf.keras.datasets.mnist

"""The images in the MNIST dataset are divided into two sets: a **training set** of images that we will use to train the neural network (`x_train`, `y_train`) and a **test set** of previously unseen images that we will use to evaluate the performance of the neural network (`x_test`, `y_test`)."""

(x_train, y_train), (x_test, y_test) = data.load_data()

"""Let's explore the training set and the test set to get a better understanding of this data. **How many images are in the training set? How many images are in the test set? What is the size of each of these images?**"""

print(x_train.shape)
print(x_test.shape)

"""Let's also print the first image in the training set and its corresponding **class label** to see what it looks like. **What digit is in this image?**"""

import matplotlib.pyplot as plt
print(y_train[-1]) # class label
print(x_train[-1]) # image
plt.imshow(x_train[-1]) # visualization of image

"""**Try changing the index of `x_train` and `y_train` to print other images. What is the digit in the second image? What is the digit in the third image? What is the digit in the last image?**

Notice that each image in `x_train` is represented by a 28x28 matrix filled with values between 0 and 255. **What do these values represent?**

When we are training a neural network, it's easier if all the values are between 0 and 1, so we **normalize** the values in `x_train` and `x_test`.
"""

x_train = x_train / 255.0
x_test = x_test / 255.0

"""Let's now design our neural network with a sequence of **layers**. For each layer, we specify the number of **neurons** and an **activation function**.

First, we have the **input** (**Flatten**) layer, which "flattens" (i.e., reshapes) the data from a 3D array to a 2D array.

We follow this with a **hidden** (**Dense**) layer. This layer has 16 neurons and `relu` as the activation function.

Finally, we have the **output** (**Dense**) layer. This layer has 10 neurons and `softmax` as the activation function. Notice that the number of neurons in this last layer should match the **number of classes** in the data.


"""

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer
  tf.keras.layers.Dense(16, activation=tf.nn.relu), # hidden layer
  tf.keras.layers.Dense(10, activation=tf.nn.softmax) # output layer
])
model.summary()

"""We compile our neural network by specifying the loss function (`sparse_categorical_crossentropy`) and the optimization algorithm (`adam`), as well as a **metric** to evaluate the performance of the neural network. In this case, we use **accuracy** (that is, the fraction of images correctly classified) as the evaluation metric."""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""We then train our neural network to fit the training data."""

model.fit(x_train, y_train, epochs=5)

"""Once it's done training, notice the accuracy at the end of the final epoch. It should be around 95%, which means that 95% of the images in the training set were classified correctly.

**But how well does our neural network do with unseen images?** To find out, we try to classify the images in the test set.
"""

predictions = model.predict(x_test)
print(predictions[1]) # output
print(np.around(predictions[1], 1)) # rounded output

print(y_test[1]) # class label
plt.imshow(x_test[1]) # visualization of image

"""Notice that the output for each image is a list of numbers. **What do these numbers represent? What is the predicted class label for the first image in the test set? Was this image classified correctly?**

We can also evaluate the performance of our neural network on the test set.
"""

model.evaluate(x_test, y_test)

"""The accuracy on the test set should be around 94%, which means that 94% of the images in the test set were classified correctly. This is still very good, but it's lower than the accuracy on the training set, which is expected. **But can we do any better?**

## **Activity**
In this activity, you have to experiment with the **structure** of the neural network that we just built by changing the number of neurons in the hidden layer. Your goal is to **maximize the accuracy on the test set**, while **minimizing the number of neurons**.

Create a neural network with the same number of layers and activation functions as above, but with different numbers of neurons in the hidden layer. **Try using 32, 64, 128, and 256 neurons**.
"""

model = tf.keras.models.Sequential([
  tf.keras.layers.Flatten(input_shape=(28, 28)), # input layer
  tf.keras.layers.Dense(16, activation=tf.nn.relu), # hidden layer
  tf.keras.layers.Dense(10, activation=tf.nn.softmax) # output layer
])
model.summary()

"""Compile the neural network. Use the same loss function, optimization algorithm, and metric as above."""

model.compile(optimizer='adam',
              loss='sparse_categorical_crossentropy',
              metrics=['accuracy'])

"""Train the neural network for **5** epochs."""

model.fit(x_train, y_train, epochs=5)

"""Evaluate the performance of the neural network on the test set."""

model.evaluate(x_test, y_test)

"""**What is the accuracy of the neural network on the test set using 16, 32, 64, 128, and 256 neurons? How does the time that takes to train the neural network change as we increase the number of neurons? How many neurons would you ultimately choose for this neural network?**

**Answer:** The higher the number of neurons, the higher accuracy and lower loss. However, 64 neurons will take up the least space and the difference in accuracy between 64, 128, and 256 neurons don't make it worth the extra space.

**Overfitting** - too complext and performs very well on training data, but performs poorly on the test data. It does not generalize well

**Underfitting** - model is too simple and does not perform well on the data. 

**Balanced** - not too simple but not too complex
"""
